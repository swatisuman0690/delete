{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c66fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "• Create a new MLP with any given number of inputs, any number of\n",
    "outputs (can be sigmoidal or linear), and any number of hidden\n",
    "units (sigmoidal/tanh) in a single layer.\n",
    "• Initialise the weights of the MLP to small random values\n",
    "• Predict the outputs corresponding to an input vector\n",
    "• Implement learning by backpropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87608f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        self.no_of_inputs = ni\n",
    "        self.no_of_hidden_units = nh\n",
    "        self.no_of_outputs = no\n",
    "        self.w1 = []\n",
    "        self.w2 = []\n",
    "        self.dw1 = []\n",
    "        self.dw2 = []\n",
    "        self.z1 = []\n",
    "        self.z2 = []\n",
    "        self.h = []\n",
    "        self.o = []\n",
    "\n",
    "    def Sigmoid(self, sig_input, der=False):\n",
    "        if der:\n",
    "            return np.exp(-sig_input) / (1 + np.exp(-sig_input)) ** 2\n",
    "        else:\n",
    "            return 1 / (1 + np.exp(-sig_input))\n",
    "\n",
    "    def Tanh(self, tanh_input, der=False):\n",
    "        if der:\n",
    "            return 1 - (np.power(self.Tanh(tanh_input), 2))\n",
    "        else:\n",
    "            return (2 / (1 + np.exp(tanh_input * -2))) - 1\n",
    "\n",
    "    def randomise(self):\n",
    "        self.w1 = np.array((np.random.uniform(0.0, 1, (self.no_of_inputs,self.no_of_hidden_units))).tolist())\n",
    "        self.dw1 = np.dot(self.w1, 0)\n",
    "        self.w2 = np.array((np.random.uniform(0.0, 1, (self.no_of_hidden_units, self.no_of_outputs))).tolist())\n",
    "        self.dw2 = np.dot(self.w2, 0)\n",
    "\n",
    "    def forward(self, input_vectors, tan=False):\n",
    "        self.z1 = np.dot(input_vectors, self.w1)\n",
    "        if tan:\n",
    "            self.h = self.Tanh(self.z1)\n",
    "        else:\n",
    "            self.h = self.Sigmoid(self.z1)\n",
    "\n",
    "        self.z2 = np.dot(self.h, self.w2)\n",
    "        if tan:\n",
    "            self.o = self.Tanh(self.z2)\n",
    "        else:\n",
    "            self.o = self.Sigmoid(self.z2)\n",
    "\n",
    "    def backwards(self, input_vectors, target, tan=False):\n",
    "        output_error = np.subtract(target, self.o)\n",
    "        if tan:\n",
    "            activation_out_2 = self.Tanh(self.z2, True)\n",
    "            activation_out_1 = self.Tanh(self.z1, True)\n",
    "        else:\n",
    "            activation_out_2 = self.Sigmoid(self.z2, True)\n",
    "            activation_out_1 = self.Sigmoid(self.z1, True)\n",
    "\n",
    "        dw2_a = np.multiply(output_error, activation_out_2)\n",
    "        self.dw2 = np.dot(self.h.T, dw2_a)\n",
    "        dw1_a = np.multiply(np.dot(dw2_a, self.w2.T), activation_out_1)\n",
    "        self.dw1 = np.dot(input_vectors.T, dw1_a)\n",
    "        return np.mean(np.abs(output_error))\n",
    "\n",
    "    def updateWeights(self, learning_rate):\n",
    "        self.w1 = self.w1 + (learning_rate * self.dw1)\n",
    "        self.w2 = self.w2 + (learning_rate * self.dw2)\n",
    "        self.dw1 = 0\n",
    "        self.dw2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f240fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734f283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Training Testing: \n",
      "Desired Output: [0]\n",
      "Predicted Output: [0.73497243]\n",
      "Desired Output: [1]\n",
      "Predicted Output: [0.75492189]\n",
      "Desired Output: [1]\n",
      "Predicted Output: [0.76945373]\n",
      "Desired Output: [0]\n",
      "Predicted Output: [0.78668195]\n",
      "\n",
      "After Training: \n",
      "Epoch: 1000   Error: 0.49840015458399994\n",
      "Epoch: 2000   Error: 0.1545451073718641\n",
      "Epoch: 3000   Error: 0.07557727369432107\n",
      "Epoch: 4000   Error: 0.055876231630467364\n",
      "Epoch: 5000   Error: 0.04602011276370544\n",
      "Epoch: 6000   Error: 0.039835911785095546\n",
      "Epoch: 7000   Error: 0.03548186646788337\n",
      "Epoch: 8000   Error: 0.03219253229516872\n",
      "Epoch: 9000   Error: 0.029585839662957157\n",
      "Epoch: 10000   Error: 0.027447505278416783\n",
      "\n",
      "Testing:\n",
      "Desired Output: [0]\n",
      "Predicted Output: [0.03028019]\n",
      "Desired Output: [1]\n",
      "Predicted Output: [0.97206353]\n",
      "Desired Output: [1]\n",
      "Predicted Output: [0.97375232]\n",
      "Desired Output: [0]\n",
      "Predicted Output: [0.02531787]\n"
     ]
    }
   ],
   "source": [
    "xorI = np.array([[0, 0], \n",
    "                 [0, 1], \n",
    "                 [1, 0], \n",
    "                 [1, 1]])\n",
    "xorO = np.array([[0], \n",
    "                 [1], \n",
    "                 [1], \n",
    "                 [0]])\n",
    "\n",
    "no_of_epochs = 10000\n",
    "learning_rate = 0.5\n",
    "inputs = 2\n",
    "hidden = 4\n",
    "outputs = 1\n",
    "mlp = MLP(inputs, hidden, outputs)\n",
    "mlp.randomise()\n",
    "\n",
    "print('Pre-Training Testing: ')\n",
    "for i in range(len(xorI)):\n",
    "    mlp.forward(xorI[i])\n",
    "    print('Desired Output: ' + str(xorO[i]))\n",
    "    print('Predicted Output: ' + str(mlp.o))\n",
    "\n",
    "print()\n",
    "print('After Training: ')\n",
    "for i in range(0, no_of_epochs):\n",
    "    error = 0\n",
    "    mlp.forward(xorI)\n",
    "    error = mlp.backwards(xorI, xorO)\n",
    "    mlp.updateWeights(learning_rate)\n",
    "    if (i + 1) % (no_of_epochs/10) == 0:\n",
    "        length = len(str(i))\n",
    "        while length < 10:\n",
    "            length += 1\n",
    "        print('Epoch: ' + str(i + 1) + \"  \" + ' Error: ' + str(error))\n",
    "\n",
    "print()\n",
    "print('Testing:')\n",
    "for i in range(len(xorI)):\n",
    "    mlp.forward(xorI[i])\n",
    "    print('Desired Output: ' + str(xorO[i]))\n",
    "    print('Predicted Output: ' + str(mlp.o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a934af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Training Testing: \n",
      "Desired Output: [0]\n",
      "Predicted Output: [0.80017308]\n",
      "Desired Output: [1]\n",
      "Predicted Output: [0.83844586]\n",
      "Desired Output: [1]\n",
      "Predicted Output: [0.85095028]\n",
      "Desired Output: [0]\n",
      "Predicted Output: [0.87662252]\n",
      "\n",
      "After Training: \n",
      "Epoch: 10000   Error: 0.020732000813817028\n",
      "Epoch: 20000   Error: 0.01429237287801423\n",
      "Epoch: 30000   Error: 0.011550069258578682\n",
      "Epoch: 40000   Error: 0.009942939190735045\n",
      "Epoch: 50000   Error: 0.008857192169068589\n",
      "Epoch: 60000   Error: 0.008061225259450217\n",
      "Epoch: 70000   Error: 0.007445742506199956\n",
      "Epoch: 80000   Error: 0.006951582949193435\n",
      "Epoch: 90000   Error: 0.006543577682919596\n",
      "Epoch: 100000   Error: 0.006199340225340663\n",
      "\n",
      "Testing:\n",
      "Desired Output: [0]\n",
      "Predicted Output: [0.01004773]\n",
      "Desired Output: [1]\n",
      "Predicted Output: [0.99334685]\n",
      "Desired Output: [1]\n",
      "Predicted Output: [0.99405099]\n",
      "Desired Output: [0]\n",
      "Predicted Output: [0.00214735]\n"
     ]
    }
   ],
   "source": [
    "xorI = np.array([[0, 0], \n",
    "                 [0, 1], \n",
    "                 [1, 0], \n",
    "                 [1, 1]])\n",
    "xorO = np.array([[0], \n",
    "                 [1], \n",
    "                 [1], \n",
    "                 [0]])\n",
    "\n",
    "no_of_epochs = 100000\n",
    "learning_rate = 0.8\n",
    "inputs = 2\n",
    "hidden = 4\n",
    "outputs = 1\n",
    "mlp = MLP(inputs, hidden, outputs)\n",
    "mlp.randomise()\n",
    "\n",
    "print('Pre-Training Testing: ')\n",
    "for i in range(len(xorI)):\n",
    "    mlp.forward(xorI[i])\n",
    "    print('Desired Output: ' + str(xorO[i]))\n",
    "    print('Predicted Output: ' + str(mlp.o))\n",
    "\n",
    "print()\n",
    "print('After Training: ')\n",
    "for i in range(0, no_of_epochs):\n",
    "    error = 0\n",
    "    mlp.forward(xorI)\n",
    "    error = mlp.backwards(xorI, xorO)\n",
    "    mlp.updateWeights(learning_rate)\n",
    "    if (i + 1) % (no_of_epochs/10) == 0:\n",
    "        length = len(str(i))\n",
    "        while length < 10:\n",
    "            length += 1\n",
    "        print('Epoch: ' + str(i + 1) + \"  \" + ' Error: ' + str(error))\n",
    "\n",
    "print()\n",
    "print('Testing:')\n",
    "for i in range(len(xorI)):\n",
    "    mlp.forward(xorI[i])\n",
    "    print('Desired Output: ' + str(xorO[i]))\n",
    "    print('Predicted Output: ' + str(mlp.o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generate 500 vectors containing 4 components each. The value of each\n",
    "component should be a random number between -1 and 1. These will be\n",
    "your input vectors. The corresponding output for each vector should be\n",
    "the sin() of a combination of the components. Specifically, for inputs:\n",
    "[x1 x2 x3 x4]\n",
    "the (single component) output should be:\n",
    "sin(x1-x2+x3-x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e51e0b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors :  [[ 0.80391536 -0.17693245 -0.04653189  0.44280551]\n",
      " [-0.75560637  0.0061301   0.62629533  0.35468372]\n",
      " [-0.35669855  0.42133079  0.8688792   0.78955248]\n",
      " ...\n",
      " [-0.03621634 -0.84375492  0.82021168  0.11845148]\n",
      " [ 0.04997233 -0.46609622  0.79998577 -0.97217286]\n",
      " [-0.80599773 -0.87985015 -0.51815531 -0.00630158]]\n",
      "\n",
      "No. of Vectors :  500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "sin_output = []\n",
    "for i in range(0, 500):\n",
    "    vector = list(np.random.uniform(-1.0, 1.0, 4))\n",
    "    vector = [float(vector[0]), float(vector[1]), float(vector[2]), float(vector[3])]\n",
    "    vectors.append(vector)\n",
    "\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "for i in range(0, 500):\n",
    "    for j in range(0,1):\n",
    "        sin_output.append([np.sin(vectors[i][j]-vectors[i][j+1]+vectors[i][j+2]-vectors[i][j+3])])\n",
    "\n",
    "sin_output = np.array(sin_output)\n",
    "\n",
    "print('Vectors : ',vectors)\n",
    "print()\n",
    "print('No. of Vectors : ',len(vectors))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5f06d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin_output [[ 5.55152784e-02]\n",
      " [-8.81696982e-01]\n",
      " [ 9.99507841e-01]\n",
      " [-9.82161545e-01]\n",
      " [-5.10941597e-01]\n",
      " [ 5.14674249e-01]\n",
      " [-8.43326586e-01]\n",
      " [ 6.95118081e-01]\n",
      " [ 5.92269351e-01]\n",
      " [-6.29596727e-02]\n",
      " [-6.24174761e-01]\n",
      " [ 7.79369434e-01]\n",
      " [-7.65349771e-01]\n",
      " [ 9.35302745e-01]\n",
      " [ 9.69542509e-01]\n",
      " [-7.28533242e-01]\n",
      " [-9.99884502e-01]\n",
      " [ 8.51614075e-02]\n",
      " [-5.38915484e-01]\n",
      " [ 6.10362608e-01]\n",
      " [-9.51132151e-01]\n",
      " [-5.16229280e-01]\n",
      " [-7.87887572e-01]\n",
      " [ 7.42108697e-01]\n",
      " [-4.33588121e-01]\n",
      " [ 6.39323089e-02]\n",
      " [-8.80868429e-01]\n",
      " [ 7.96515499e-01]\n",
      " [ 8.77838067e-01]\n",
      " [ 6.56914064e-01]\n",
      " [-8.91408571e-01]\n",
      " [-6.41369632e-01]\n",
      " [-2.50683044e-01]\n",
      " [-5.01625289e-01]\n",
      " [-7.99158648e-01]\n",
      " [-5.27976007e-01]\n",
      " [-9.54372532e-01]\n",
      " [ 1.04354803e-02]\n",
      " [ 1.99774665e-01]\n",
      " [ 8.01660302e-01]\n",
      " [-9.17066683e-01]\n",
      " [-3.94573792e-01]\n",
      " [-1.22230144e-01]\n",
      " [-8.93597524e-01]\n",
      " [ 9.72358076e-01]\n",
      " [-8.23474303e-02]\n",
      " [-9.00917000e-01]\n",
      " [-6.01928342e-01]\n",
      " [-2.26709452e-01]\n",
      " [-9.95209079e-01]\n",
      " [-9.77278163e-01]\n",
      " [-2.90021063e-01]\n",
      " [ 7.22945359e-01]\n",
      " [-9.45239628e-01]\n",
      " [-3.59371006e-01]\n",
      " [-3.71637940e-01]\n",
      " [-6.51691584e-01]\n",
      " [-9.97418496e-01]\n",
      " [-6.51259888e-01]\n",
      " [-1.02354698e-01]\n",
      " [ 9.98878263e-01]\n",
      " [ 1.10547669e-01]\n",
      " [ 8.27896321e-01]\n",
      " [-9.78867367e-01]\n",
      " [ 6.72318068e-01]\n",
      " [-9.83273225e-01]\n",
      " [-7.34583461e-01]\n",
      " [ 6.85474606e-01]\n",
      " [ 8.09081722e-01]\n",
      " [ 1.11400076e-01]\n",
      " [-3.63062886e-01]\n",
      " [ 5.42847625e-01]\n",
      " [-3.15315306e-01]\n",
      " [-1.65726028e-01]\n",
      " [-1.37834724e-01]\n",
      " [-7.58388463e-01]\n",
      " [-9.90687807e-01]\n",
      " [ 8.02411863e-01]\n",
      " [-4.65838351e-01]\n",
      " [-2.19997909e-01]\n",
      " [-7.94734187e-01]\n",
      " [ 9.99340791e-01]\n",
      " [ 5.47413090e-01]\n",
      " [ 2.81579823e-01]\n",
      " [ 8.59342777e-01]\n",
      " [ 9.99999327e-01]\n",
      " [ 9.91584298e-01]\n",
      " [-9.63242353e-01]\n",
      " [ 9.74380013e-01]\n",
      " [ 9.61482191e-01]\n",
      " [ 5.29078119e-01]\n",
      " [-8.74852337e-01]\n",
      " [ 3.86251695e-02]\n",
      " [-7.15475882e-01]\n",
      " [-8.64010405e-01]\n",
      " [-8.70576851e-01]\n",
      " [-9.85067725e-01]\n",
      " [ 8.72277254e-01]\n",
      " [ 9.42218711e-01]\n",
      " [ 3.32814411e-02]\n",
      " [-6.91578741e-01]\n",
      " [-6.43865693e-01]\n",
      " [ 7.24065673e-01]\n",
      " [ 1.09655552e-01]\n",
      " [ 7.53963848e-01]\n",
      " [-1.46502066e-01]\n",
      " [-7.79628349e-01]\n",
      " [-2.08114902e-01]\n",
      " [ 9.20625688e-01]\n",
      " [-9.98724087e-01]\n",
      " [ 6.38872137e-01]\n",
      " [ 9.99032539e-01]\n",
      " [ 9.96158756e-01]\n",
      " [-9.72980922e-01]\n",
      " [-9.71248846e-01]\n",
      " [ 2.09032474e-01]\n",
      " [-2.64468799e-01]\n",
      " [-6.91076375e-01]\n",
      " [ 9.99999387e-01]\n",
      " [-4.33573933e-04]\n",
      " [ 9.96907787e-01]\n",
      " [ 9.80601072e-01]\n",
      " [-9.99345262e-03]\n",
      " [-1.62756219e-01]\n",
      " [ 5.59496287e-01]\n",
      " [ 9.25659131e-01]\n",
      " [ 9.80749319e-01]\n",
      " [ 7.13071471e-01]\n",
      " [-2.91733412e-01]\n",
      " [-4.38197096e-01]\n",
      " [ 9.04497017e-01]\n",
      " [ 9.15971394e-01]\n",
      " [ 2.05240738e-01]\n",
      " [ 8.08129034e-01]\n",
      " [ 5.66650906e-01]\n",
      " [-8.19054262e-01]\n",
      " [ 5.04207278e-01]\n",
      " [ 5.25147506e-01]\n",
      " [ 6.57324506e-02]\n",
      " [ 7.86162421e-01]\n",
      " [ 9.99560332e-01]\n",
      " [-9.26575768e-01]\n",
      " [ 8.80293902e-01]\n",
      " [-5.95359883e-01]\n",
      " [-5.25047218e-01]\n",
      " [-8.93264682e-01]\n",
      " [-8.93293464e-01]\n",
      " [-9.46955459e-01]\n",
      " [-3.15720035e-02]\n",
      " [-8.75348731e-01]\n",
      " [ 7.11196576e-01]\n",
      " [-7.10399412e-01]\n",
      " [ 6.05199939e-01]\n",
      " [ 9.95517271e-01]\n",
      " [-9.21315899e-01]\n",
      " [ 8.32962770e-01]\n",
      " [ 8.36430057e-01]\n",
      " [ 1.61846374e-01]\n",
      " [ 7.77985095e-01]\n",
      " [-9.41366690e-01]\n",
      " [ 7.57456415e-03]\n",
      " [ 7.54271185e-01]\n",
      " [-9.49565484e-01]\n",
      " [ 6.44671706e-01]\n",
      " [ 2.73642036e-01]\n",
      " [-4.93463126e-01]\n",
      " [-8.45307735e-01]\n",
      " [ 8.97984805e-01]\n",
      " [-6.04353366e-01]\n",
      " [ 2.72399128e-01]\n",
      " [ 7.37972242e-01]\n",
      " [-9.12793800e-01]\n",
      " [ 2.33001618e-01]\n",
      " [ 9.91173327e-01]\n",
      " [-9.56643783e-01]\n",
      " [ 9.99973205e-01]\n",
      " [-9.20615898e-02]\n",
      " [ 9.98360772e-01]\n",
      " [ 7.39618481e-01]\n",
      " [ 5.44006988e-01]\n",
      " [-7.06697951e-01]\n",
      " [-3.95710949e-01]\n",
      " [-6.18283332e-01]\n",
      " [-6.78175040e-01]\n",
      " [-9.20501563e-01]\n",
      " [ 5.34013882e-01]\n",
      " [ 6.94057937e-01]\n",
      " [ 9.94185780e-01]\n",
      " [ 5.91459465e-01]\n",
      " [-6.29297318e-01]\n",
      " [ 8.40511021e-01]\n",
      " [-8.02092286e-01]\n",
      " [-9.70706255e-01]\n",
      " [-9.43333072e-01]\n",
      " [ 7.04906140e-01]\n",
      " [-9.99184580e-01]\n",
      " [ 1.02403229e-01]\n",
      " [ 6.74781888e-01]\n",
      " [ 4.16540468e-01]\n",
      " [ 9.73773118e-01]\n",
      " [ 6.44798932e-01]\n",
      " [-2.18998636e-01]\n",
      " [-6.29824725e-01]\n",
      " [-6.39989852e-01]\n",
      " [-9.99047773e-01]\n",
      " [ 9.95035111e-01]\n",
      " [ 7.18356909e-01]\n",
      " [-1.45238644e-02]\n",
      " [-3.60101684e-01]\n",
      " [-1.47927139e-01]\n",
      " [-4.73261591e-01]\n",
      " [-8.38964509e-01]\n",
      " [ 9.77812134e-01]\n",
      " [ 4.94535849e-01]\n",
      " [ 9.29856912e-01]\n",
      " [ 9.99264295e-01]\n",
      " [ 1.76859112e-01]\n",
      " [ 8.70179946e-01]\n",
      " [ 9.98250866e-01]\n",
      " [ 3.84678447e-03]\n",
      " [ 7.88352135e-01]\n",
      " [ 9.83513209e-01]\n",
      " [ 1.45683346e-01]\n",
      " [-2.03955412e-01]\n",
      " [-9.99359974e-01]\n",
      " [ 6.98304956e-01]\n",
      " [-4.00305848e-01]\n",
      " [-9.93377756e-01]\n",
      " [-9.93862243e-01]\n",
      " [-6.24646342e-01]\n",
      " [-8.44370917e-01]\n",
      " [-9.68817720e-01]\n",
      " [-3.50225762e-01]\n",
      " [ 2.44910385e-02]\n",
      " [-1.19039964e-01]\n",
      " [ 1.87354523e-01]\n",
      " [ 1.83112633e-01]\n",
      " [-7.84106163e-01]\n",
      " [-9.73714346e-01]\n",
      " [ 9.78700323e-01]\n",
      " [ 5.04221306e-01]\n",
      " [ 7.85430636e-01]\n",
      " [-4.46287233e-01]\n",
      " [-9.99183580e-01]\n",
      " [-9.12716345e-01]\n",
      " [-4.32648797e-02]\n",
      " [-7.40442843e-01]\n",
      " [ 2.70290340e-01]\n",
      " [-9.83719236e-01]\n",
      " [-8.63157394e-01]\n",
      " [ 9.66453691e-01]\n",
      " [-5.85797942e-01]\n",
      " [ 7.49814346e-01]\n",
      " [ 5.29545407e-01]\n",
      " [-7.37369328e-01]\n",
      " [ 9.40610211e-01]\n",
      " [-4.64894248e-01]\n",
      " [ 9.99982561e-01]\n",
      " [-8.12831014e-01]\n",
      " [ 9.69880614e-02]\n",
      " [ 8.04533790e-02]\n",
      " [-6.91142840e-01]\n",
      " [-4.40049367e-01]\n",
      " [-3.12711517e-01]\n",
      " [-2.93663949e-01]\n",
      " [-4.98529213e-01]\n",
      " [-8.68801227e-01]\n",
      " [-5.08403479e-01]\n",
      " [-5.27129478e-01]\n",
      " [-9.81659319e-01]\n",
      " [ 9.16609118e-01]\n",
      " [ 2.78519689e-01]\n",
      " [-3.56261088e-01]\n",
      " [ 9.40528014e-01]\n",
      " [ 9.84561239e-01]\n",
      " [-9.19297579e-01]\n",
      " [ 4.92304352e-01]\n",
      " [ 5.37609339e-01]\n",
      " [ 5.18478671e-01]\n",
      " [-9.51128472e-01]\n",
      " [-5.15986295e-01]\n",
      " [ 7.80054734e-01]\n",
      " [ 7.90624425e-01]\n",
      " [-9.58808162e-01]\n",
      " [ 1.39250831e-01]\n",
      " [-9.90413099e-01]\n",
      " [ 3.45548917e-01]\n",
      " [ 3.47770796e-01]\n",
      " [-9.46722110e-01]\n",
      " [-4.84313832e-01]\n",
      " [ 8.92689258e-01]\n",
      " [ 8.07905067e-01]\n",
      " [ 9.85584612e-01]\n",
      " [-3.88970984e-02]\n",
      " [ 9.00090125e-01]\n",
      " [-9.79547213e-01]\n",
      " [-5.07154228e-01]\n",
      " [-9.99081367e-01]\n",
      " [ 3.96267181e-01]\n",
      " [-5.41503465e-01]\n",
      " [-9.18081117e-01]\n",
      " [-5.22103026e-01]\n",
      " [-9.79426965e-01]\n",
      " [ 9.42166266e-01]\n",
      " [-9.39575862e-01]\n",
      " [-3.59439117e-01]\n",
      " [-8.59146775e-01]\n",
      " [-9.95206125e-01]\n",
      " [ 9.40747364e-01]\n",
      " [-9.04574066e-01]\n",
      " [-1.38690870e-01]\n",
      " [-7.88066751e-01]\n",
      " [-5.49368332e-01]\n",
      " [-6.30455590e-01]\n",
      " [ 9.99943418e-01]\n",
      " [ 4.46112072e-01]\n",
      " [-9.24930890e-01]\n",
      " [-9.86400217e-01]\n",
      " [ 9.17444425e-01]\n",
      " [-3.58764372e-01]\n",
      " [ 2.86735094e-01]\n",
      " [-5.43383951e-02]\n",
      " [-9.25806625e-01]\n",
      " [ 5.57199854e-01]\n",
      " [ 8.01796973e-01]\n",
      " [ 9.56265978e-01]\n",
      " [ 5.29345074e-01]\n",
      " [-1.69450814e-01]\n",
      " [-5.42201862e-01]\n",
      " [ 3.79431064e-01]\n",
      " [-9.87204145e-01]\n",
      " [-8.86690012e-01]\n",
      " [ 4.88758246e-01]\n",
      " [ 7.99137049e-01]\n",
      " [-8.23684266e-01]\n",
      " [-1.57334435e-01]\n",
      " [ 9.99979471e-01]\n",
      " [-9.39644863e-01]\n",
      " [-8.90620643e-01]\n",
      " [-9.70732919e-01]\n",
      " [ 9.82178107e-01]\n",
      " [-7.37182385e-01]\n",
      " [-2.92282543e-01]\n",
      " [ 8.59657598e-01]\n",
      " [ 7.17349003e-01]\n",
      " [ 1.08678010e-01]\n",
      " [ 2.76806405e-02]\n",
      " [-9.98278056e-01]\n",
      " [-4.35793910e-02]\n",
      " [-8.86671157e-01]\n",
      " [-7.15888706e-01]\n",
      " [-9.99993730e-01]\n",
      " [ 8.58696479e-01]\n",
      " [-7.21924616e-01]\n",
      " [-9.66042670e-01]\n",
      " [-5.68278029e-01]\n",
      " [ 8.87338394e-01]\n",
      " [ 1.69865548e-01]\n",
      " [ 6.39510314e-01]\n",
      " [ 9.50378744e-01]\n",
      " [ 1.32324661e-01]\n",
      " [ 1.65370288e-01]\n",
      " [ 4.52975057e-01]\n",
      " [ 8.26255830e-01]\n",
      " [ 5.41451600e-01]\n",
      " [ 9.97502136e-01]\n",
      " [ 6.81715729e-01]\n",
      " [ 9.88752110e-01]\n",
      " [-3.22913939e-01]\n",
      " [-4.98773492e-01]\n",
      " [-9.99782858e-01]\n",
      " [-9.17632213e-01]\n",
      " [ 3.29494813e-01]\n",
      " [-6.84059229e-02]\n",
      " [-4.67495650e-01]\n",
      " [-3.70989217e-02]\n",
      " [ 6.78851069e-01]\n",
      " [-8.98042272e-01]\n",
      " [-9.80168770e-01]\n",
      " [-8.25811488e-01]\n",
      " [ 3.37565061e-01]\n",
      " [-9.94842033e-01]\n",
      " [ 5.73745907e-01]\n",
      " [ 1.21243396e-01]\n",
      " [-9.50383808e-01]\n",
      " [ 6.15139271e-01]\n",
      " [ 8.93970871e-01]\n",
      " [-8.35482613e-01]\n",
      " [-1.48458579e-01]\n",
      " [-1.36416538e-01]\n",
      " [ 7.55802918e-01]\n",
      " [-2.10358419e-01]\n",
      " [-3.07573790e-02]\n",
      " [ 7.82375327e-01]\n",
      " [-9.69376274e-01]\n",
      " [-6.74978898e-01]\n",
      " [ 5.87899926e-01]\n",
      " [ 9.88486546e-01]\n",
      " [-1.10284502e-01]\n",
      " [ 1.51493110e-03]\n",
      " [-5.00159952e-01]\n",
      " [ 4.04325435e-01]\n",
      " [-4.64076562e-01]\n",
      " [-6.00540315e-01]\n",
      " [-3.58150380e-01]\n",
      " [-7.00241055e-01]\n",
      " [-2.74915938e-01]\n",
      " [ 6.01363270e-01]\n",
      " [ 9.97650690e-01]\n",
      " [-6.24244223e-01]\n",
      " [-7.11762692e-01]\n",
      " [-9.45179191e-01]\n",
      " [-7.48859112e-01]\n",
      " [-1.07879266e-01]\n",
      " [-2.10476556e-01]\n",
      " [-9.90597708e-01]\n",
      " [-8.01941121e-01]\n",
      " [-3.48524730e-01]\n",
      " [-8.63881804e-01]\n",
      " [-8.70312791e-01]\n",
      " [-9.45388742e-01]\n",
      " [-7.47666915e-02]\n",
      " [-7.12501565e-01]\n",
      " [-1.79602026e-01]\n",
      " [ 9.39704923e-01]\n",
      " [ 9.44276514e-01]\n",
      " [-1.51089757e-01]\n",
      " [ 9.82956777e-01]\n",
      " [ 9.97948328e-01]\n",
      " [ 9.44868711e-01]\n",
      " [ 9.71237349e-01]\n",
      " [-9.94537285e-01]\n",
      " [-9.97535375e-01]\n",
      " [-1.45779131e-01]\n",
      " [-8.12249655e-01]\n",
      " [ 2.99309122e-01]\n",
      " [-7.94718772e-01]\n",
      " [ 9.85468753e-01]\n",
      " [ 4.16174954e-01]\n",
      " [-9.80751071e-03]\n",
      " [-3.58249502e-01]\n",
      " [-5.34076038e-01]\n",
      " [ 9.83870786e-01]\n",
      " [-2.93196144e-02]\n",
      " [ 2.11426200e-01]\n",
      " [-7.95358622e-01]\n",
      " [-9.28708648e-02]\n",
      " [ 2.90756704e-01]\n",
      " [-7.71970605e-01]\n",
      " [ 8.93270804e-01]\n",
      " [ 8.73562753e-01]\n",
      " [-5.31658735e-01]\n",
      " [ 7.78205905e-01]\n",
      " [ 4.99730516e-01]\n",
      " [-2.52350339e-01]\n",
      " [-5.61697564e-01]\n",
      " [ 3.42749052e-01]\n",
      " [-6.80124638e-01]\n",
      " [ 9.99433359e-01]\n",
      " [-8.82074424e-01]\n",
      " [ 6.63477844e-03]\n",
      " [ 2.14093939e-01]\n",
      " [-5.17094854e-01]\n",
      " [ 9.69971535e-01]\n",
      " [ 6.10861879e-01]\n",
      " [-7.10585353e-01]\n",
      " [ 9.19730121e-01]\n",
      " [-9.91486724e-01]\n",
      " [-2.72525783e-01]\n",
      " [-5.50508817e-03]\n",
      " [ 1.65385951e-01]\n",
      " [ 3.49146678e-01]\n",
      " [-1.04720820e-02]\n",
      " [-9.01491049e-01]\n",
      " [ 5.73975176e-01]\n",
      " [ 1.81224687e-01]\n",
      " [ 9.52306695e-01]\n",
      " [ 3.69702804e-01]\n",
      " [ 4.28532386e-01]\n",
      " [ 9.93133362e-01]\n",
      " [-5.62316785e-01]\n",
      " [-9.91136623e-01]\n",
      " [ 2.44923189e-01]\n",
      " [-2.24712893e-01]\n",
      " [-1.81604875e-01]\n",
      " [-7.03891630e-01]\n",
      " [-7.76425788e-01]\n",
      " [-9.82145674e-01]\n",
      " [ 5.06675630e-01]\n",
      " [-5.54882138e-01]\n",
      " [ 9.51749618e-01]\n",
      " [ 9.21832574e-01]\n",
      " [ 3.41123720e-01]\n",
      " [-2.09199171e-02]\n",
      " [ 1.16723238e-01]\n",
      " [ 8.82701379e-01]\n",
      " [ 2.62814667e-01]\n",
      " [ 1.76822573e-01]\n",
      " [ 7.42589821e-01]\n",
      " [ 6.81498322e-02]]\n"
     ]
    }
   ],
   "source": [
    "print('Sin_output',sin_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d839bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Training Testing:\n",
      "Desired Output: [0.95174962]\n",
      "Predicted Output: [-0.59234067]\n",
      "Desired Output: [0.92183257]\n",
      "Predicted Output: [-0.61652474]\n",
      "Desired Output: [0.34112372]\n",
      "Predicted Output: [0.50004275]\n",
      "Desired Output: [-0.02091992]\n",
      "Predicted Output: [0.45006627]\n",
      "Desired Output: [0.11672324]\n",
      "Predicted Output: [0.3245332]\n",
      "Desired Output: [0.88270138]\n",
      "Predicted Output: [-0.37757419]\n",
      "Desired Output: [0.26281467]\n",
      "Predicted Output: [0.44385276]\n",
      "Desired Output: [0.17682257]\n",
      "Predicted Output: [-0.78165503]\n",
      "Desired Output: [0.74258982]\n",
      "Predicted Output: [-0.44201102]\n",
      "Desired Output: [0.06814983]\n",
      "Predicted Output: [0.82716567]\n",
      "\n",
      "After Training: \n",
      "Epoch: 50000   Error: 0.07627983856088585\n",
      "Epoch: 100000   Error: 0.0762804191915113\n",
      "Epoch: 150000   Error: 0.07628041933058104\n",
      "Epoch: 200000   Error: 0.07628041933061142\n",
      "Epoch: 250000   Error: 0.07628041933061142\n",
      "Epoch: 300000   Error: 0.07628041933061142\n",
      "Epoch: 350000   Error: 0.07628041933061142\n",
      "Epoch: 400000   Error: 0.07628041933061142\n",
      "Epoch: 450000   Error: 0.07628041933061142\n",
      "Epoch: 500000   Error: 0.07628041933061142\n",
      "\n",
      "Testing: \n",
      "Desired Output: [-0.50015995]\n",
      "Predicted Output: [-0.54100944]\n",
      "Desired Output: [0.40432544]\n",
      "Predicted Output: [0.45860887]\n",
      "Desired Output: [-0.46407656]\n",
      "Predicted Output: [-0.48551584]\n",
      "Desired Output: [-0.60054031]\n",
      "Predicted Output: [-0.94941136]\n",
      "Desired Output: [-0.35815038]\n",
      "Predicted Output: [-0.3957739]\n",
      "Desired Output: [-0.70024105]\n",
      "Predicted Output: [-0.71962818]\n",
      "Desired Output: [-0.27491594]\n",
      "Predicted Output: [-0.36063391]\n",
      "Desired Output: [0.60136327]\n",
      "Predicted Output: [0.60095391]\n",
      "Desired Output: [0.99765069]\n",
      "Predicted Output: [0.83137702]\n",
      "Desired Output: [-0.62424422]\n",
      "Predicted Output: [-0.66583294]\n",
      "Desired Output: [-0.71176269]\n",
      "Predicted Output: [-0.69631752]\n",
      "Desired Output: [-0.94517919]\n",
      "Predicted Output: [-0.8211551]\n",
      "Desired Output: [-0.74885911]\n",
      "Predicted Output: [-0.74189263]\n",
      "Desired Output: [-0.10787927]\n",
      "Predicted Output: [-0.07121411]\n",
      "Desired Output: [-0.21047656]\n",
      "Predicted Output: [-0.29551798]\n",
      "Desired Output: [-0.99059771]\n",
      "Predicted Output: [-0.96173521]\n",
      "Desired Output: [-0.80194112]\n",
      "Predicted Output: [-0.73296531]\n",
      "Desired Output: [-0.34852473]\n",
      "Predicted Output: [-0.58071127]\n",
      "Desired Output: [-0.8638818]\n",
      "Predicted Output: [-0.80265221]\n",
      "Desired Output: [-0.87031279]\n",
      "Predicted Output: [-0.96803178]\n",
      "Desired Output: [-0.94538874]\n",
      "Predicted Output: [-0.81912875]\n",
      "Desired Output: [-0.07476669]\n",
      "Predicted Output: [-0.169286]\n",
      "Desired Output: [-0.71250157]\n",
      "Predicted Output: [-0.71840461]\n",
      "Desired Output: [-0.17960203]\n",
      "Predicted Output: [-0.2934245]\n",
      "Desired Output: [0.93970492]\n",
      "Predicted Output: [0.97648145]\n",
      "Desired Output: [0.94427651]\n",
      "Predicted Output: [0.83353937]\n",
      "Desired Output: [-0.15108976]\n",
      "Predicted Output: [-0.00938144]\n",
      "Desired Output: [0.98295678]\n",
      "Predicted Output: [0.92682254]\n",
      "Desired Output: [0.99794833]\n",
      "Predicted Output: [0.93142924]\n",
      "Desired Output: [0.94486871]\n",
      "Predicted Output: [0.91109784]\n",
      "Desired Output: [0.97123735]\n",
      "Predicted Output: [0.92603881]\n",
      "Desired Output: [-0.99453728]\n",
      "Predicted Output: [-0.77946159]\n",
      "Desired Output: [-0.99753537]\n",
      "Predicted Output: [-0.83712578]\n",
      "Desired Output: [-0.14577913]\n",
      "Predicted Output: [-0.23551028]\n",
      "Desired Output: [-0.81224966]\n",
      "Predicted Output: [-0.77962857]\n",
      "Desired Output: [0.29930912]\n",
      "Predicted Output: [0.26689907]\n",
      "Desired Output: [-0.79471877]\n",
      "Predicted Output: [-0.79034113]\n",
      "Desired Output: [0.98546875]\n",
      "Predicted Output: [0.93287588]\n",
      "Desired Output: [0.41617495]\n",
      "Predicted Output: [0.54351827]\n",
      "Desired Output: [-0.00980751]\n",
      "Predicted Output: [0.11002746]\n",
      "Desired Output: [-0.3582495]\n",
      "Predicted Output: [-0.33745006]\n",
      "Desired Output: [-0.53407604]\n",
      "Predicted Output: [-0.56578775]\n",
      "Desired Output: [0.98387079]\n",
      "Predicted Output: [0.90553932]\n",
      "Desired Output: [-0.02931961]\n",
      "Predicted Output: [-0.02283595]\n",
      "Desired Output: [0.2114262]\n",
      "Predicted Output: [0.48786918]\n",
      "Desired Output: [-0.79535862]\n",
      "Predicted Output: [-0.7783036]\n",
      "Desired Output: [-0.09287086]\n",
      "Predicted Output: [-0.08138039]\n",
      "Desired Output: [0.2907567]\n",
      "Predicted Output: [0.42447192]\n",
      "Desired Output: [-0.77197061]\n",
      "Predicted Output: [-0.76725569]\n",
      "Desired Output: [0.8932708]\n",
      "Predicted Output: [0.8330477]\n",
      "Desired Output: [0.87356275]\n",
      "Predicted Output: [0.7654433]\n",
      "Desired Output: [-0.53165873]\n",
      "Predicted Output: [-0.63470672]\n",
      "Desired Output: [0.7782059]\n",
      "Predicted Output: [0.92441829]\n",
      "Desired Output: [0.49973052]\n",
      "Predicted Output: [0.6599811]\n",
      "Desired Output: [-0.25235034]\n",
      "Predicted Output: [-0.20687385]\n",
      "Desired Output: [-0.56169756]\n",
      "Predicted Output: [-0.60095057]\n",
      "Desired Output: [0.34274905]\n",
      "Predicted Output: [0.56561328]\n",
      "Desired Output: [-0.68012464]\n",
      "Predicted Output: [-0.72436142]\n",
      "Desired Output: [0.99943336]\n",
      "Predicted Output: [0.82887553]\n",
      "Desired Output: [-0.88207442]\n",
      "Predicted Output: [-0.79845002]\n",
      "Desired Output: [0.00663478]\n",
      "Predicted Output: [-0.17579011]\n",
      "Desired Output: [0.21409394]\n",
      "Predicted Output: [0.30505306]\n",
      "Desired Output: [-0.51709485]\n",
      "Predicted Output: [-0.63588732]\n",
      "Desired Output: [0.96997153]\n",
      "Predicted Output: [0.89594506]\n",
      "Desired Output: [0.61086188]\n",
      "Predicted Output: [0.74967546]\n",
      "Desired Output: [-0.71058535]\n",
      "Predicted Output: [-0.72846519]\n",
      "Desired Output: [0.91973012]\n",
      "Predicted Output: [0.91344199]\n",
      "Desired Output: [-0.99148672]\n",
      "Predicted Output: [-0.93627071]\n",
      "Desired Output: [-0.27252578]\n",
      "Predicted Output: [-0.85707035]\n",
      "Desired Output: [-0.00550509]\n",
      "Predicted Output: [0.0140471]\n",
      "Desired Output: [0.16538595]\n",
      "Predicted Output: [0.22700135]\n",
      "Desired Output: [0.34914668]\n",
      "Predicted Output: [0.27591943]\n",
      "Desired Output: [-0.01047208]\n",
      "Predicted Output: [-0.11071072]\n",
      "Desired Output: [-0.90149105]\n",
      "Predicted Output: [-0.82939118]\n",
      "Desired Output: [0.57397518]\n",
      "Predicted Output: [0.71550082]\n",
      "Desired Output: [0.18122469]\n",
      "Predicted Output: [0.47621854]\n",
      "Desired Output: [0.9523067]\n",
      "Predicted Output: [0.90291723]\n",
      "Desired Output: [0.3697028]\n",
      "Predicted Output: [0.42537587]\n",
      "Desired Output: [0.42853239]\n",
      "Predicted Output: [0.63747659]\n",
      "Desired Output: [0.99313336]\n",
      "Predicted Output: [0.88131779]\n",
      "Desired Output: [-0.56231678]\n",
      "Predicted Output: [-0.61824107]\n",
      "Desired Output: [-0.99113662]\n",
      "Predicted Output: [-0.81635772]\n",
      "Desired Output: [0.24492319]\n",
      "Predicted Output: [0.24476623]\n",
      "Desired Output: [-0.22471289]\n",
      "Predicted Output: [-0.36609534]\n",
      "Desired Output: [-0.18160487]\n",
      "Predicted Output: [-0.10929477]\n",
      "Desired Output: [-0.70389163]\n",
      "Predicted Output: [-0.72605636]\n",
      "Desired Output: [-0.77642579]\n",
      "Predicted Output: [-0.76426135]\n",
      "Desired Output: [-0.98214567]\n",
      "Predicted Output: [-0.93030416]\n",
      "Desired Output: [0.50667563]\n",
      "Predicted Output: [0.53309298]\n",
      "Desired Output: [-0.55488214]\n",
      "Predicted Output: [-0.49116392]\n",
      "Desired Output: [0.95174962]\n",
      "Predicted Output: [0.82840847]\n",
      "Desired Output: [0.92183257]\n",
      "Predicted Output: [0.85173266]\n",
      "Desired Output: [0.34112372]\n",
      "Predicted Output: [0.43345283]\n",
      "Desired Output: [-0.02091992]\n",
      "Predicted Output: [-0.3721611]\n",
      "Desired Output: [0.11672324]\n",
      "Predicted Output: [0.10915146]\n",
      "Desired Output: [0.88270138]\n",
      "Predicted Output: [0.8328876]\n",
      "Desired Output: [0.26281467]\n",
      "Predicted Output: [0.3719]\n",
      "Desired Output: [0.17682257]\n",
      "Predicted Output: [0.10597857]\n",
      "Desired Output: [0.74258982]\n",
      "Predicted Output: [0.75004126]\n",
      "Desired Output: [0.06814983]\n",
      "Predicted Output: [0.17248369]\n"
     ]
    }
   ],
   "source": [
    "no_of_epochs = 500000\n",
    "learning_rate = 0.005\n",
    "inputs = 4\n",
    "hidden = 5\n",
    "outputs = 1\n",
    "\n",
    "mlp = MLP(inputs, hidden, outputs)\n",
    "mlp.randomise()\n",
    "\n",
    "print('Pre-Training Testing:')\n",
    "for i in range(len(vectors) - 10, len(vectors)):\n",
    "    mlp.forward(vectors[i],tan=True)\n",
    "    print('Desired Output: ' + str(sin_output[i]))\n",
    "    print('Predicted Output: ' + str(mlp.o))\n",
    "\n",
    "print()\n",
    "print('After Training: ')\n",
    "for i in range(0, no_of_epochs):\n",
    "    error = 0\n",
    "    mlp.forward(vectors[:len(vectors) - 100], tan=True)\n",
    "    error = mlp.backwards(vectors[:(len(vectors) - 100)], sin_output[:len(vectors) - 100], tan=True)\n",
    "    mlp.updateWeights(learning_rate)\n",
    "    if (i + 1) % (no_of_epochs / 10) == 0:\n",
    "        length = len(str(i))\n",
    "        while length < 100:\n",
    "            length += 1\n",
    "        print('Epoch: ' + str(i + 1) + \"   \" + 'Error: ' + str(error))\n",
    "\n",
    "print()\n",
    "print('Testing: ')\n",
    "for i in range(len(vectors) - 100, len(vectors)):\n",
    "    mlp.forward(vectors[i], tan=True)\n",
    "    print('Desired Output: ' + str(sin_output[i]))\n",
    "    print('Predicted Output: ' + str(mlp.o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a9ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9279f53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors :  [[ 0.64891922  0.70794483  0.19165988 -0.51965253]\n",
      " [-0.62701462  0.48678102 -0.52557188  0.07898178]\n",
      " [ 0.49856157 -0.54350179 -0.65099762 -0.92052863]\n",
      " ...\n",
      " [-0.79219778 -0.88674729  0.36159207 -0.95473057]\n",
      " [-0.91140182 -0.92609395 -0.06917898  0.51573889]\n",
      " [ 0.98439845 -0.54678461  0.58476045  0.59049173]]\n",
      "\n",
      "No. of Vectors :  500\n",
      "\n",
      "Desired Output: [[ 0.60700531]\n",
      " [-0.98913379]\n",
      " [ 0.96659483]\n",
      " [-0.99719166]\n",
      " [-0.99678733]\n",
      " [-0.54206054]\n",
      " [ 0.94271374]\n",
      " [-0.42426779]\n",
      " [ 0.79231036]\n",
      " [ 0.99972331]\n",
      " [-0.07738182]\n",
      " [ 0.61586142]\n",
      " [ 0.53240204]\n",
      " [ 0.11899111]\n",
      " [-0.41673364]\n",
      " [-0.82737773]\n",
      " [-0.96486581]\n",
      " [ 0.23299549]\n",
      " [-0.02854615]\n",
      " [-0.53843437]\n",
      " [ 0.97729839]\n",
      " [ 0.82178514]\n",
      " [ 0.09120354]\n",
      " [ 0.39274528]\n",
      " [ 0.56078333]\n",
      " [-0.62922765]\n",
      " [-0.29170923]\n",
      " [ 0.99929032]\n",
      " [ 0.52726513]\n",
      " [-0.69913498]\n",
      " [-0.99970134]\n",
      " [-0.33513993]\n",
      " [ 0.72365388]\n",
      " [ 0.98998447]\n",
      " [-0.12049866]\n",
      " [ 0.97053859]\n",
      " [ 0.9801065 ]\n",
      " [ 0.21199843]\n",
      " [-0.92329646]\n",
      " [-0.92650043]\n",
      " [ 0.67388722]\n",
      " [-0.4836189 ]\n",
      " [-0.99785413]\n",
      " [-0.97854747]\n",
      " [ 0.31863918]\n",
      " [-0.38443137]\n",
      " [ 0.20911842]\n",
      " [ 0.37504518]\n",
      " [ 0.48957544]\n",
      " [-0.31898501]\n",
      " [-0.87466113]\n",
      " [-0.43538777]\n",
      " [-0.58197924]\n",
      " [ 0.73800425]\n",
      " [ 0.36924416]\n",
      " [-0.70183853]\n",
      " [ 0.99226994]\n",
      " [ 0.36768905]\n",
      " [-0.04002813]\n",
      " [ 0.61730465]\n",
      " [ 0.01508541]\n",
      " [-0.13213154]\n",
      " [ 0.08859063]\n",
      " [-0.81256976]\n",
      " [-0.28238542]\n",
      " [ 0.99143663]\n",
      " [-0.89140516]\n",
      " [-0.27637338]\n",
      " [-0.99971996]\n",
      " [-0.99748361]\n",
      " [-0.99794066]\n",
      " [ 0.07506785]\n",
      " [ 0.99470131]\n",
      " [-0.93944516]\n",
      " [-0.65266593]\n",
      " [ 0.98029806]\n",
      " [ 0.94254768]\n",
      " [-0.7730593 ]\n",
      " [ 0.34157091]\n",
      " [ 0.46559343]\n",
      " [-0.50305459]\n",
      " [-0.99822003]\n",
      " [ 0.90022111]\n",
      " [ 0.9927845 ]\n",
      " [ 0.92443766]\n",
      " [-0.67456677]\n",
      " [ 0.5661259 ]\n",
      " [-0.83798005]\n",
      " [ 0.97465178]\n",
      " [ 0.06823958]\n",
      " [ 0.23436035]\n",
      " [-0.28126696]\n",
      " [ 0.89887435]\n",
      " [-0.5327518 ]\n",
      " [ 0.83197247]\n",
      " [-0.36061488]\n",
      " [-0.944782  ]\n",
      " [-0.20054739]\n",
      " [ 0.43840943]\n",
      " [ 0.24702335]\n",
      " [ 0.82716427]\n",
      " [-0.67189392]\n",
      " [-0.1487192 ]\n",
      " [ 0.64813102]\n",
      " [ 0.95007534]\n",
      " [ 0.86860075]\n",
      " [-0.29783138]\n",
      " [ 0.84658816]\n",
      " [ 0.74983703]\n",
      " [ 0.15462208]\n",
      " [-0.25718147]\n",
      " [-0.95067614]\n",
      " [-0.69437456]\n",
      " [-0.48869577]\n",
      " [ 0.61992574]\n",
      " [-0.99043401]\n",
      " [-0.31494222]\n",
      " [-0.3392446 ]\n",
      " [-0.999767  ]\n",
      " [ 0.79994275]\n",
      " [-0.78297404]\n",
      " [-0.43658025]\n",
      " [-0.82877901]\n",
      " [ 0.95013892]\n",
      " [ 0.57934039]\n",
      " [-0.93043704]\n",
      " [-0.85171194]\n",
      " [-0.96410979]\n",
      " [-0.80964214]\n",
      " [-0.23140657]\n",
      " [-0.03610668]\n",
      " [ 0.62617434]\n",
      " [-0.54499272]\n",
      " [-0.19801004]\n",
      " [ 0.55023451]\n",
      " [-0.97397015]\n",
      " [-0.97738678]\n",
      " [-0.84066071]\n",
      " [-0.67578839]\n",
      " [-0.48044912]\n",
      " [-0.79413157]\n",
      " [ 0.68095868]\n",
      " [-0.96634797]\n",
      " [-0.92307246]\n",
      " [ 0.05067768]\n",
      " [-0.5445284 ]\n",
      " [-0.01802607]\n",
      " [-0.34687246]\n",
      " [-0.46302107]\n",
      " [ 0.91700734]\n",
      " [-0.47310304]\n",
      " [ 0.92864271]\n",
      " [-0.48859658]\n",
      " [ 0.0069798 ]\n",
      " [-0.56100096]\n",
      " [-0.3692157 ]\n",
      " [ 0.6699558 ]\n",
      " [-0.95439927]\n",
      " [-0.59374773]\n",
      " [ 0.85047219]\n",
      " [ 0.12700914]\n",
      " [ 0.99771494]\n",
      " [ 0.66500305]\n",
      " [ 0.08738352]\n",
      " [ 0.91470812]\n",
      " [-0.63478305]\n",
      " [ 0.80773482]\n",
      " [ 0.44699064]\n",
      " [-0.42384748]\n",
      " [-0.86590283]\n",
      " [-0.38852088]\n",
      " [ 0.79683678]\n",
      " [-0.02332867]\n",
      " [-0.82750553]\n",
      " [ 0.99295976]\n",
      " [-0.45882194]\n",
      " [ 0.11309273]\n",
      " [-0.39522144]\n",
      " [ 0.96665136]\n",
      " [ 0.40685454]\n",
      " [-0.98118678]\n",
      " [ 0.53357498]\n",
      " [-0.79661748]\n",
      " [-0.83111272]\n",
      " [ 0.93525191]\n",
      " [ 0.75656702]\n",
      " [-0.12591123]\n",
      " [-0.88698508]\n",
      " [-0.9902778 ]\n",
      " [-0.66575677]\n",
      " [ 0.28341012]\n",
      " [-0.73041683]\n",
      " [ 0.95961898]\n",
      " [ 0.97697393]\n",
      " [ 0.87272951]\n",
      " [-0.78572368]\n",
      " [-0.12974755]\n",
      " [-0.79397924]\n",
      " [-0.42921965]\n",
      " [-0.31975759]\n",
      " [ 0.78378046]\n",
      " [-0.99644075]\n",
      " [-0.87215146]\n",
      " [-0.70582495]\n",
      " [ 0.20272632]\n",
      " [ 0.94735861]\n",
      " [ 0.42305472]\n",
      " [ 0.22048907]\n",
      " [ 0.60208041]\n",
      " [ 0.3246943 ]\n",
      " [-0.52447716]\n",
      " [ 0.99929054]\n",
      " [-0.82878299]\n",
      " [ 0.59552416]\n",
      " [ 0.46326821]\n",
      " [-0.83721252]\n",
      " [ 0.57688892]\n",
      " [ 0.58047906]\n",
      " [-0.03892717]\n",
      " [ 0.8829106 ]\n",
      " [ 0.3014428 ]\n",
      " [ 0.89456638]\n",
      " [ 0.00735123]\n",
      " [-0.26814727]\n",
      " [ 0.39277117]\n",
      " [ 0.87608884]\n",
      " [-0.5313299 ]\n",
      " [-0.23214621]\n",
      " [-0.2224895 ]\n",
      " [-0.36144028]\n",
      " [ 0.28871942]\n",
      " [ 0.0603351 ]\n",
      " [-0.17846994]\n",
      " [-0.44803532]\n",
      " [ 0.04420388]\n",
      " [-0.988232  ]\n",
      " [ 0.21404243]\n",
      " [ 0.01332894]\n",
      " [-0.27408962]\n",
      " [-0.99949436]\n",
      " [-0.99428063]\n",
      " [ 0.97685396]\n",
      " [ 0.46978222]\n",
      " [-0.4621537 ]\n",
      " [-0.46941796]\n",
      " [ 0.98053036]\n",
      " [-0.96348914]\n",
      " [-0.71565393]\n",
      " [ 0.91984913]\n",
      " [-0.22343828]\n",
      " [ 0.28601607]\n",
      " [-0.24429838]\n",
      " [-0.96472752]\n",
      " [ 0.98203103]\n",
      " [ 0.99999858]\n",
      " [ 0.73615914]\n",
      " [ 0.24108126]\n",
      " [-0.81229316]\n",
      " [ 0.53008015]\n",
      " [-0.19221955]\n",
      " [-0.47783958]\n",
      " [ 0.641369  ]\n",
      " [-0.68565344]\n",
      " [-0.91520979]\n",
      " [-0.58337759]\n",
      " [ 0.91066717]\n",
      " [ 0.46177704]\n",
      " [-0.48255756]\n",
      " [-0.57388876]\n",
      " [-0.97264286]\n",
      " [ 0.90877067]\n",
      " [-0.8455199 ]\n",
      " [-0.52251888]\n",
      " [ 0.99954802]\n",
      " [-0.08494134]\n",
      " [ 0.90396563]\n",
      " [-0.9945964 ]\n",
      " [ 0.20846388]\n",
      " [-0.61520804]\n",
      " [-0.35032034]\n",
      " [ 0.98242944]\n",
      " [ 0.62582828]\n",
      " [-0.64297633]\n",
      " [-0.74543778]\n",
      " [ 0.97665163]\n",
      " [-0.80410572]\n",
      " [ 0.85312987]\n",
      " [ 0.84437172]\n",
      " [-0.45025664]\n",
      " [ 0.99939944]\n",
      " [ 0.71454061]\n",
      " [-0.92770464]\n",
      " [-0.99948389]\n",
      " [-0.87854917]\n",
      " [ 0.94245977]\n",
      " [-0.98464484]\n",
      " [-0.73586386]\n",
      " [-0.14438685]\n",
      " [ 0.84500138]\n",
      " [ 0.4920537 ]\n",
      " [-0.42539527]\n",
      " [ 0.88708582]\n",
      " [-0.30974505]\n",
      " [-0.66343491]\n",
      " [-0.38982925]\n",
      " [-0.85379333]\n",
      " [ 0.64539618]\n",
      " [ 0.76477464]\n",
      " [-0.99848389]\n",
      " [-0.27793291]\n",
      " [ 0.0739558 ]\n",
      " [ 0.16434825]\n",
      " [ 0.55647333]\n",
      " [ 0.70539873]\n",
      " [-0.13999739]\n",
      " [ 0.43859466]\n",
      " [ 0.4664641 ]\n",
      " [ 0.96896808]\n",
      " [-0.27141338]\n",
      " [-0.05943378]\n",
      " [ 0.6719814 ]\n",
      " [-0.64721025]\n",
      " [ 0.78255082]\n",
      " [-0.99950947]\n",
      " [ 0.861232  ]\n",
      " [-0.36399045]\n",
      " [ 0.34877022]\n",
      " [-0.41912697]\n",
      " [-0.77005633]\n",
      " [ 0.0642115 ]\n",
      " [-0.16624139]\n",
      " [-0.70694595]\n",
      " [-0.66359935]\n",
      " [ 0.5192399 ]\n",
      " [-0.29275072]\n",
      " [ 0.40010476]\n",
      " [-0.99343609]\n",
      " [-0.95099314]\n",
      " [-0.87866626]\n",
      " [-0.6741921 ]\n",
      " [-0.58154972]\n",
      " [ 0.97210343]\n",
      " [ 0.27229898]\n",
      " [ 0.93885034]\n",
      " [-0.37112665]\n",
      " [ 0.99995838]\n",
      " [ 0.52971066]\n",
      " [ 0.61076439]\n",
      " [ 0.86116367]\n",
      " [ 0.97174314]\n",
      " [ 0.87195158]\n",
      " [ 0.9432226 ]\n",
      " [-0.08814289]\n",
      " [-0.64830748]\n",
      " [-0.96784445]\n",
      " [-0.11360224]\n",
      " [ 0.95323894]\n",
      " [ 0.97390605]\n",
      " [ 0.74610314]\n",
      " [-0.18863214]\n",
      " [-0.59822965]\n",
      " [-0.66887531]\n",
      " [ 0.57537683]\n",
      " [-0.78774394]\n",
      " [ 0.56898073]\n",
      " [ 0.47435371]\n",
      " [-0.94817904]\n",
      " [ 0.79840502]\n",
      " [ 0.73216006]\n",
      " [ 0.63546036]\n",
      " [ 0.66781819]\n",
      " [ 0.43656757]\n",
      " [-0.95130977]\n",
      " [-0.30049628]\n",
      " [ 0.07871766]\n",
      " [ 0.14952993]\n",
      " [-0.97963947]\n",
      " [-0.91635011]\n",
      " [-0.76323241]\n",
      " [-0.6598131 ]\n",
      " [ 0.86005543]\n",
      " [ 0.9871557 ]\n",
      " [ 0.71078328]\n",
      " [ 0.76952989]\n",
      " [ 0.80292371]\n",
      " [-0.51231536]\n",
      " [-0.74401769]\n",
      " [-0.78738352]\n",
      " [-0.16839543]\n",
      " [ 0.91252115]\n",
      " [-0.22811862]\n",
      " [-0.99298038]\n",
      " [ 0.25256195]\n",
      " [-0.9774786 ]\n",
      " [ 0.31209138]\n",
      " [-0.97400185]\n",
      " [ 0.34727291]\n",
      " [-0.29814899]\n",
      " [-0.5002692 ]\n",
      " [-0.84222519]\n",
      " [ 0.76398774]\n",
      " [-0.11510196]\n",
      " [ 0.56924272]\n",
      " [ 0.63765615]\n",
      " [ 0.9868431 ]\n",
      " [ 0.4341022 ]\n",
      " [-0.82143452]\n",
      " [-0.99084876]\n",
      " [-0.8489704 ]\n",
      " [-0.28225652]\n",
      " [-0.07816828]\n",
      " [ 0.27793941]\n",
      " [-0.65535131]\n",
      " [-0.14559866]\n",
      " [-0.8485222 ]\n",
      " [ 0.83995771]\n",
      " [-0.06429489]\n",
      " [-0.98261503]\n",
      " [-0.82335587]\n",
      " [-0.32290191]\n",
      " [ 0.98096951]\n",
      " [ 0.78904191]\n",
      " [-0.9777074 ]\n",
      " [ 0.94027097]\n",
      " [-0.77748455]\n",
      " [-0.33572406]\n",
      " [-0.05930625]\n",
      " [ 0.75250686]\n",
      " [-0.83263183]\n",
      " [-0.94551534]\n",
      " [ 0.99957828]\n",
      " [-0.11210821]\n",
      " [ 0.89902358]\n",
      " [ 0.19468485]\n",
      " [-0.93326665]\n",
      " [-0.98872125]\n",
      " [-0.98173426]\n",
      " [ 0.85260633]\n",
      " [-0.22052774]\n",
      " [ 0.54594623]\n",
      " [-0.99829504]\n",
      " [-0.77006682]\n",
      " [ 0.8667139 ]\n",
      " [-0.02090345]\n",
      " [ 0.84452578]\n",
      " [ 0.92663041]\n",
      " [-0.25020893]\n",
      " [-0.56607452]\n",
      " [ 0.35516222]\n",
      " [ 0.14341579]\n",
      " [ 0.64796828]\n",
      " [ 0.70307286]\n",
      " [ 0.63737966]\n",
      " [ 0.76889553]\n",
      " [ 0.99695357]\n",
      " [ 0.98440071]\n",
      " [-0.55698512]\n",
      " [ 0.99850377]\n",
      " [-0.12344521]\n",
      " [-0.69240267]\n",
      " [-0.8430666 ]\n",
      " [-0.42945244]\n",
      " [-0.06194173]\n",
      " [ 0.98998066]\n",
      " [ 0.89938699]\n",
      " [-0.67716924]\n",
      " [ 0.94913244]\n",
      " [ 0.1204744 ]\n",
      " [-0.23088612]\n",
      " [-0.85903672]\n",
      " [-0.25102756]\n",
      " [-0.79632649]\n",
      " [-0.06829587]\n",
      " [-0.07205461]\n",
      " [ 0.95466331]\n",
      " [ 0.95635666]\n",
      " [ 0.8645277 ]\n",
      " [-0.57122764]\n",
      " [ 0.18806177]\n",
      " [-0.68939513]\n",
      " [ 0.41655462]\n",
      " [ 0.02197427]\n",
      " [-0.94227085]\n",
      " [ 0.99512096]\n",
      " [-0.91885209]\n",
      " [ 0.62655688]\n",
      " [ 0.18329629]\n",
      " [-0.26022169]\n",
      " [-0.99960635]\n",
      " [ 0.6634076 ]\n",
      " [-0.84716922]\n",
      " [ 0.46180839]\n",
      " [-0.38669034]\n",
      " [ 0.80535347]\n",
      " [-0.79734836]\n",
      " [-0.97455059]\n",
      " [-0.99035055]\n",
      " [ 0.98723936]\n",
      " [-0.53982208]\n",
      " [ 0.99897211]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "vectors = []\n",
    "desired_sin_output = []\n",
    "for i in range(0, 500):\n",
    "    vector = list(np.random.uniform(-1.0, 1.0, 4))\n",
    "    vector = [float(vector[0]), float(vector[1]), float(vector[2]), float(vector[3])]\n",
    "    vectors.append(vector)\n",
    "\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "fifty_vectors_df=pd.DataFrame(vectors)\n",
    "fifty_vectors_df['target']=fifty_vectors_df[0]-fifty_vectors_df[1]+fifty_vectors_df[2]-fifty_vectors_df[3]\n",
    "fifty_vectors_df['desired_sin_output']=np.sin(fifty_vectors_df.target)\n",
    "for sin_value in fifty_vectors_df['desired_sin_output']:\n",
    "    lst1=[]\n",
    "    lst1.append(sin_value)\n",
    "    desired_sin_output.append(lst1)\n",
    "    \n",
    "desired_sin_output= np.array(desired_sin_output)\n",
    "\n",
    "print('Vectors : ',vectors)\n",
    "print()\n",
    "print('No. of Vectors : ',len(vectors))\n",
    "print()\n",
    "print('Desired Output:', desired_sin_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff499a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Training Testing:\n",
      "Desired Output: [-0.84716922]\n",
      "Predicted Output: [-0.48148005]\n",
      "Desired Output: [0.46180839]\n",
      "Predicted Output: [0.73430878]\n",
      "Desired Output: [-0.38669034]\n",
      "Predicted Output: [-0.49942051]\n",
      "Desired Output: [0.80535347]\n",
      "Predicted Output: [-0.84849657]\n",
      "Desired Output: [-0.79734836]\n",
      "Predicted Output: [-0.76221814]\n",
      "Desired Output: [-0.97455059]\n",
      "Predicted Output: [0.00639885]\n",
      "Desired Output: [-0.99035055]\n",
      "Predicted Output: [0.38889517]\n",
      "Desired Output: [0.98723936]\n",
      "Predicted Output: [-0.87938861]\n",
      "Desired Output: [-0.53982208]\n",
      "Predicted Output: [-0.36459696]\n",
      "Desired Output: [0.99897211]\n",
      "Predicted Output: [0.90188052]\n",
      "\n",
      "After Training: \n",
      "Epoch: 20000   Error: 0.08753098757793742\n",
      "Epoch: 40000   Error: 0.08844262395414045\n",
      "Epoch: 60000   Error: 0.08721349474918202\n",
      "Epoch: 80000   Error: 0.08413425350418528\n",
      "Epoch: 100000   Error: 0.08903240597124583\n",
      "Epoch: 120000   Error: 0.08962256227803536\n",
      "Epoch: 140000   Error: 0.08350173802803025\n",
      "Epoch: 160000   Error: 0.08762434694802945\n",
      "Epoch: 180000   Error: 0.08843531056805726\n",
      "Epoch: 200000   Error: 0.08622984366666779\n",
      "\n",
      "Testing: \n",
      "Desired Output: [0.76398774]\n",
      "Predicted Output: [0.75607872]\n",
      "Desired Output: [-0.11510196]\n",
      "Predicted Output: [-0.21556803]\n",
      "Desired Output: [0.56924272]\n",
      "Predicted Output: [0.5210737]\n",
      "Desired Output: [0.63765615]\n",
      "Predicted Output: [0.58116585]\n",
      "Desired Output: [0.9868431]\n",
      "Predicted Output: [0.88799771]\n",
      "Desired Output: [0.4341022]\n",
      "Predicted Output: [0.39674617]\n",
      "Desired Output: [-0.82143452]\n",
      "Predicted Output: [-0.79909997]\n",
      "Desired Output: [-0.99084876]\n",
      "Predicted Output: [-0.88432626]\n",
      "Desired Output: [-0.8489704]\n",
      "Predicted Output: [-0.82922966]\n",
      "Desired Output: [-0.28225652]\n",
      "Predicted Output: [-0.44537951]\n",
      "Desired Output: [-0.07816828]\n",
      "Predicted Output: [-0.17768297]\n",
      "Desired Output: [0.27793941]\n",
      "Predicted Output: [0.34047769]\n",
      "Desired Output: [-0.65535131]\n",
      "Predicted Output: [-0.621526]\n",
      "Desired Output: [-0.14559866]\n",
      "Predicted Output: [-0.09097289]\n",
      "Desired Output: [-0.8485222]\n",
      "Predicted Output: [-0.96575194]\n",
      "Desired Output: [0.83995771]\n",
      "Predicted Output: [0.76313979]\n",
      "Desired Output: [-0.06429489]\n",
      "Predicted Output: [-0.09578493]\n",
      "Desired Output: [-0.98261503]\n",
      "Predicted Output: [-0.88196706]\n",
      "Desired Output: [-0.82335587]\n",
      "Predicted Output: [-0.86082958]\n",
      "Desired Output: [-0.32290191]\n",
      "Predicted Output: [-0.48505586]\n",
      "Desired Output: [0.98096951]\n",
      "Predicted Output: [0.93963136]\n",
      "Desired Output: [0.78904191]\n",
      "Predicted Output: [0.78589827]\n",
      "Desired Output: [-0.9777074]\n",
      "Predicted Output: [-0.91575656]\n",
      "Desired Output: [0.94027097]\n",
      "Predicted Output: [0.90701518]\n",
      "Desired Output: [-0.77748455]\n",
      "Predicted Output: [-0.83674551]\n",
      "Desired Output: [-0.33572406]\n",
      "Predicted Output: [-0.50226667]\n",
      "Desired Output: [-0.05930625]\n",
      "Predicted Output: [0.11224575]\n",
      "Desired Output: [0.75250686]\n",
      "Predicted Output: [0.69139299]\n",
      "Desired Output: [-0.83263183]\n",
      "Predicted Output: [-0.75940149]\n",
      "Desired Output: [-0.94551534]\n",
      "Predicted Output: [-0.8281889]\n",
      "Desired Output: [0.99957828]\n",
      "Predicted Output: [0.90070369]\n",
      "Desired Output: [-0.11210821]\n",
      "Predicted Output: [-0.24968672]\n",
      "Desired Output: [0.89902358]\n",
      "Predicted Output: [0.87162327]\n",
      "Desired Output: [0.19468485]\n",
      "Predicted Output: [0.35333489]\n",
      "Desired Output: [-0.93326665]\n",
      "Predicted Output: [-0.85161056]\n",
      "Desired Output: [-0.98872125]\n",
      "Predicted Output: [-0.84586581]\n",
      "Desired Output: [-0.98173426]\n",
      "Predicted Output: [-0.95111485]\n",
      "Desired Output: [0.85260633]\n",
      "Predicted Output: [0.85421096]\n",
      "Desired Output: [-0.22052774]\n",
      "Predicted Output: [-0.04548902]\n",
      "Desired Output: [0.54594623]\n",
      "Predicted Output: [0.65026061]\n",
      "Desired Output: [-0.99829504]\n",
      "Predicted Output: [-0.94739091]\n",
      "Desired Output: [-0.77006682]\n",
      "Predicted Output: [-0.70019151]\n",
      "Desired Output: [0.8667139]\n",
      "Predicted Output: [0.66702664]\n",
      "Desired Output: [-0.02090345]\n",
      "Predicted Output: [-0.13660509]\n",
      "Desired Output: [0.84452578]\n",
      "Predicted Output: [0.79081701]\n",
      "Desired Output: [0.92663041]\n",
      "Predicted Output: [0.85732706]\n",
      "Desired Output: [-0.25020893]\n",
      "Predicted Output: [-0.15342344]\n",
      "Desired Output: [-0.56607452]\n",
      "Predicted Output: [-0.52825085]\n",
      "Desired Output: [0.35516222]\n",
      "Predicted Output: [0.55068881]\n",
      "Desired Output: [0.14341579]\n",
      "Predicted Output: [0.36777196]\n",
      "Desired Output: [0.64796828]\n",
      "Predicted Output: [0.77023634]\n",
      "Desired Output: [0.70307286]\n",
      "Predicted Output: [0.6801829]\n",
      "Desired Output: [0.63737966]\n",
      "Predicted Output: [0.74968144]\n",
      "Desired Output: [0.76889553]\n",
      "Predicted Output: [0.98058881]\n",
      "Desired Output: [0.99695357]\n",
      "Predicted Output: [0.86070391]\n",
      "Desired Output: [0.98440071]\n",
      "Predicted Output: [0.88025616]\n",
      "Desired Output: [-0.55698512]\n",
      "Predicted Output: [-0.67615047]\n",
      "Desired Output: [0.99850377]\n",
      "Predicted Output: [0.89084745]\n",
      "Desired Output: [-0.12344521]\n",
      "Predicted Output: [-0.00904488]\n",
      "Desired Output: [-0.69240267]\n",
      "Predicted Output: [-0.670273]\n",
      "Desired Output: [-0.8430666]\n",
      "Predicted Output: [-0.82075497]\n",
      "Desired Output: [-0.42945244]\n",
      "Predicted Output: [-0.37530266]\n",
      "Desired Output: [-0.06194173]\n",
      "Predicted Output: [0.17076017]\n",
      "Desired Output: [0.98998066]\n",
      "Predicted Output: [0.88603149]\n",
      "Desired Output: [0.89938699]\n",
      "Predicted Output: [0.84566638]\n",
      "Desired Output: [-0.67716924]\n",
      "Predicted Output: [-0.63120714]\n",
      "Desired Output: [0.94913244]\n",
      "Predicted Output: [0.86495855]\n",
      "Desired Output: [0.1204744]\n",
      "Predicted Output: [0.3136612]\n",
      "Desired Output: [-0.23088612]\n",
      "Predicted Output: [-0.19536701]\n",
      "Desired Output: [-0.85903672]\n",
      "Predicted Output: [-0.86767599]\n",
      "Desired Output: [-0.25102756]\n",
      "Predicted Output: [-0.14719715]\n",
      "Desired Output: [-0.79632649]\n",
      "Predicted Output: [-0.6364779]\n",
      "Desired Output: [-0.06829587]\n",
      "Predicted Output: [-0.14694187]\n",
      "Desired Output: [-0.07205461]\n",
      "Predicted Output: [-0.19609511]\n",
      "Desired Output: [0.95466331]\n",
      "Predicted Output: [0.952969]\n",
      "Desired Output: [0.95635666]\n",
      "Predicted Output: [0.91347345]\n",
      "Desired Output: [0.8645277]\n",
      "Predicted Output: [0.77388307]\n",
      "Desired Output: [-0.57122764]\n",
      "Predicted Output: [-0.6715681]\n",
      "Desired Output: [0.18806177]\n",
      "Predicted Output: [0.6264916]\n",
      "Desired Output: [-0.68939513]\n",
      "Predicted Output: [-0.70722564]\n",
      "Desired Output: [0.41655462]\n",
      "Predicted Output: [0.50558158]\n",
      "Desired Output: [0.02197427]\n",
      "Predicted Output: [-0.11305159]\n",
      "Desired Output: [-0.94227085]\n",
      "Predicted Output: [-0.72807502]\n",
      "Desired Output: [0.99512096]\n",
      "Predicted Output: [0.8420427]\n",
      "Desired Output: [-0.91885209]\n",
      "Predicted Output: [-0.93790358]\n",
      "Desired Output: [0.62655688]\n",
      "Predicted Output: [0.48060658]\n",
      "Desired Output: [0.18329629]\n",
      "Predicted Output: [0.29361218]\n",
      "Desired Output: [-0.26022169]\n",
      "Predicted Output: [-0.27862122]\n",
      "Desired Output: [-0.99960635]\n",
      "Predicted Output: [-0.93049131]\n",
      "Desired Output: [0.6634076]\n",
      "Predicted Output: [0.71649758]\n",
      "Desired Output: [-0.84716922]\n",
      "Predicted Output: [-0.80376907]\n",
      "Desired Output: [0.46180839]\n",
      "Predicted Output: [0.63922096]\n",
      "Desired Output: [-0.38669034]\n",
      "Predicted Output: [-0.37671885]\n",
      "Desired Output: [0.80535347]\n",
      "Predicted Output: [0.67081294]\n",
      "Desired Output: [-0.79734836]\n",
      "Predicted Output: [-0.76869209]\n",
      "Desired Output: [-0.97455059]\n",
      "Predicted Output: [-0.83704945]\n",
      "Desired Output: [-0.99035055]\n",
      "Predicted Output: [-0.86620483]\n",
      "Desired Output: [0.98723936]\n",
      "Predicted Output: [0.82351649]\n",
      "Desired Output: [-0.53982208]\n",
      "Predicted Output: [-0.64126862]\n",
      "Desired Output: [0.99897211]\n",
      "Predicted Output: [0.93808836]\n"
     ]
    }
   ],
   "source": [
    "no_of_epochs = 200000\n",
    "learning_rate = 0.005\n",
    "inputs = 4\n",
    "hidden = 5\n",
    "outputs = 1\n",
    "\n",
    "mlp = MLP(inputs, hidden, outputs)\n",
    "mlp.randomise()\n",
    "\n",
    "print('Pre-Training Testing:')\n",
    "for i in range(len(vectors) - 10, len(vectors)):\n",
    "    mlp.forward(vectors[i],tan=True)\n",
    "    print('Desired Output: ' + str(desired_sin_output[i]))\n",
    "    print('Predicted Output: ' + str(mlp.o))\n",
    "\n",
    "print()\n",
    "print('After Training: ')\n",
    "for i in range(0, no_of_epochs):\n",
    "    error = 0\n",
    "    mlp.forward(vectors[:len(vectors) - 100], tan=True)\n",
    "    error = mlp.backwards(vectors[:(len(vectors) - 100)], desired_sin_output[:len(vectors) - 100], tan=True)\n",
    "    mlp.updateWeights(learning_rate)\n",
    "    if (i + 1) % (no_of_epochs / 10) == 0:\n",
    "        length = len(str(i))\n",
    "        while length < 100:\n",
    "            length += 1\n",
    "        print('Epoch: ' + str(i + 1) + \"   \" + 'Error: ' + str(error))\n",
    "\n",
    "print()\n",
    "print('Testing: ')\n",
    "for i in range(len(vectors) - 100, len(vectors)):\n",
    "    mlp.forward(vectors[i], tan=True)\n",
    "    print('Desired Output: ' + str(desired_sin_output[i]))\n",
    "    print('Predicted Output: ' + str(mlp.o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5efe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50e595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc0b35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "training_data = []\n",
    "desired_output = []\n",
    "desired_output_numbers = []\n",
    "\n",
    "df = pd.read_csv(\"letter-recognition.data\", header = None)\n",
    "df = df.rename(columns = {0:'Letters'})\n",
    "#with open('letter_recognition_data.csv', 'r') as f:\n",
    "#   for line in f:\n",
    " #       training_data.append(line.rstrip('\\n').split(','))\n",
    "  #      desired_output.append(line.rstrip('\\n').split(',')[0])\n",
    "\n",
    "#for i in range(len(desired_output)):\n",
    " #   desired_output_numbers.append(ord(str(desired_output[i]).lower()) - 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26f23e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Letters  1   2  3  4  5   6   7  8  9  10  11  12  13  14  15  16\n",
       "0           T  2   8  3  5  1   8  13  0  6   6  10   8   0   8   0   8\n",
       "1           I  5  12  3  7  2  10   5  5  4  13   3   9   2   8   4  10\n",
       "2           D  4  11  6  8  6  10   6  2  6  10   3   7   3   7   3   9\n",
       "3           N  7  11  6  6  3   5   9  4  6   4   4  10   6  10   2   8\n",
       "4           G  2   1  3  1  1   8   6  6  6   6   5   9   1   7   5  10\n",
       "...       ... ..  .. .. .. ..  ..  .. .. ..  ..  ..  ..  ..  ..  ..  ..\n",
       "19995       D  2   2  3  3  2   7   7  7  6   6   6   4   2   8   3   7\n",
       "19996       C  7  10  8  8  4   4   8  6  9  12   9  13   2   9   3   7\n",
       "19997       T  6   9  6  7  5   6  11  3  7  11   9   5   2  12   2   4\n",
       "19998       S  2   3  4  2  1   8   7  2  6  10   6   8   1   9   5   8\n",
       "19999       A  4   9  6  6  2   9   5  3  1   8   1   8   2   7   2   8\n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c5939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_output = df.pop('Letters').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6d34518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['T', 'I', 'D', ..., 'T', 'S', 'A'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddbb1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "491f3fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  8,  3, ...,  8,  0,  8],\n",
       "       [ 5, 12,  3, ...,  8,  4, 10],\n",
       "       [ 4, 11,  6, ...,  7,  3,  9],\n",
       "       ...,\n",
       "       [ 6,  9,  6, ..., 12,  2,  4],\n",
       "       [ 2,  3,  4, ...,  9,  5,  8],\n",
       "       [ 4,  9,  6, ...,  7,  2,  8]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3552fa05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de4bed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pre-Training Testing:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (16,) and (4,5) not aligned: 16 (dim 0) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4260/2960011537.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pre-Training Testing:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Desired Output: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesired_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted Output: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4260/2663836905.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_vectors, tan)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (16,) and (4,5) not aligned: 16 (dim 0) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "no_of_epochs = 1000\n",
    "learning_rate = 0.05\n",
    "inputs = 16\n",
    "hidden = 10\n",
    "outputs = 26\n",
    "print()\n",
    "\n",
    "print('Pre-Training Testing:')\n",
    "for i in range(len(training_data)):\n",
    "    mlp.forward(training_data[i])\n",
    "    print('Desired Output: ' + str(desired_output[i]))\n",
    "    print('Predicted Output: ' + str(mlp.o))\n",
    "\n",
    "print()\n",
    "print('After Training: ')\n",
    "for i in range(0, no_of_epochs):\n",
    "    error = 0\n",
    "    mlp.forward(training_data[:len(training_data) - 10], tan=True)\n",
    "    error = mlp.backwards(training_data[:(len(training_data) - 10)], sin_output[:len(training_data) - 10], tan=True)\n",
    "    mlp.updateWeights(learning_rate)\n",
    "    if (i + 1) % (no_of_epochs / 10) == 0:\n",
    "        length = len(str(i))\n",
    "        while length < 10:\n",
    "            length += 1\n",
    "        print('Epoch: ' + str(i + 1) + \"   \" + 'Error: ' + str(error))\n",
    "\n",
    "print()\n",
    "print('Testing: ')\n",
    "for i in range(len(training_data) - 10, len(training_data)):\n",
    "    mlp.forward(training_data[i], tan=True)\n",
    "    print('Desired Output: ' + str(desired_output[i]))\n",
    "    print('Predicted Output: ' + str(mlp.o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c744c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb9864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e0d7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import urllib\n",
    "\n",
    "data = pd.read_csv(\"letter-recognition.data\", header = None)\n",
    "data = data.rename(columns = {0:'Letters'})\n",
    "y = data.pop('Letters').values\n",
    "X = data.values\n",
    "\n",
    "# Split the data into a training set and a testing set\n",
    "n_samples = len(X)\n",
    "n_train = int(0.8 * n_samples)\n",
    "X_train = X[:n_train,:]\n",
    "y_train = y[:n_train]\n",
    "X_test = X[n_train:,:]\n",
    "y_test = y[n_train:]\n",
    "\n",
    "# Normalize the input features\n",
    "X_train = X_train / 16.0\n",
    "X_test = X_test / 16.0\n",
    "\n",
    "# Define the architecture of the MLP\n",
    "n_inputs = 16\n",
    "n_hidden = 10\n",
    "n_outputs = 26\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.uniform(size=(n_inputs, n_hidden))\n",
    "b1 = np.zeros(n_hidden)\n",
    "W2 = np.random.uniform(size=(n_hidden, n_outputs))\n",
    "b2 = np.zeros(n_outputs)\n",
    "\n",
    "# Define the activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the forward propagation function\n",
    "def forward_prop(X, W1, b1, W2, b2):\n",
    "    Z1 = X.dot(W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = A1.dot(W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return A2\n",
    "\n",
    "# Define the backpropagation function\n",
    "def backprop(X, y, A2, W1, b1, W2, b2):\n",
    "    m = len(y)\n",
    "    dZ2 = A2 - y\n",
    "    dW2 = 1/m * np.dot(A1.T, dZ2)\n",
    "    db2 = 1/m * np.sum(dZ2, axis=0)\n",
    "    dZ1 = np.dot(dZ2, W2.T) * A1 * (1 - A1)\n",
    "    dW1 = 1/m * np.dot(X.T, dZ1)\n",
    "    db1 = 1/m * np.sum(dZ1, axis=0)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# Define the update function\n",
    "def update(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    b2 -= learning_rate * db2\n",
    "    W2 -= learning_rate * dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fd6fbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on pre training dataset: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Use the trained MLP to make predictions on the testing set\n",
    "y_pred = forward_prop(X_test, W1, b1, W2, b2)\n",
    "\n",
    "# Evaluate the classification accuracy on the testing set\n",
    "accuracy = np.mean(np.argmax(y_pred, axis=1) == y_test)\n",
    "print('Classification accuracy on pre training dataset:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da4f54c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (16000,26) (16000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4260/4185414231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Backpropagate the error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Update the weights and biases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4260/1980385714.py\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(X, y, A2, W1, b1, W2, b2)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mdZ2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mdW2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdZ2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mdb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (16000,26) (16000,) "
     ]
    }
   ],
   "source": [
    "# Set the number of epochs and the learning rate\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Train the MLP for 1000 epochs\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward propagate the input\n",
    "    A2 = forward_prop(X_train, W1, b1, W2, b2)\n",
    "\n",
    "    # Backpropagate the error\n",
    "    dW1, db1, dW2, db2 = backprop(X_train, y_train, A2, W1, b1, W2, b2)\n",
    "\n",
    "    # Update the weights and biases\n",
    "    W1, b1, W2, b2 = update(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "\n",
    "# Use the trained MLP to make predictions on the testing set\n",
    "y_pred = forward_prop(X_test, W1, b1, W2, b2)\n",
    "\n",
    "# Evaluate the classification accuracy on the testing set\n",
    "accuracy = np.mean(np.argmax(y_pred, axis=1) == y_test)\n",
    "print('Classification accuracy on testing set:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a35a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be1dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514f770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705119b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887bdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077a66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148ce21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c0765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
